# robot-teach-thyself

Inspired by a recent podcast of Lex Fridman and Yann LeCun regarding machine learning and comparitive biological learning. Self improvement and learning has been an obsession of mine for as long as I can remember. Sluicing self directed learning pursuits against less subjective systems (such as university degree or trade federation requirements) seems like it ought to provide some mechanism for scoring the value of learning in hopefully a more objective way. 

I also tend mentally to gamify everything that interests me--and this is no exception. 

Idea: How would you teach a robot to play chess ...and where are others in this process. 

[ ] Current state: Has this problem already been solved... 
* If so, where are the frontiers in that solution... is there anything else to be contributed here and what is the barrier to entry in doing so?
* What about Deep Blue?!? True, these are maybe the first obvious response; but I'm interested more in chess as a problem set--not in beating a human player, but instead in some abstraction/entity developing the capacity to recognize that there is this pre-existing thing called chess, it has rules, it has history and richness and provides inspiration and potential to develop patterns of thought or action in an observer that can learn. 

Aside: Not aiming at playing faster, better, cheaper, ...yet, or maybe even ever. At this most basic level even the idea of extruding USD from the efforts might be anti-thetical, though who doesn't want more flex--not a criticism so much as just holding off that interest until the genesis of the idea has germinated. Perhaps at that point maybe further relying on economic/market principles and capital allocation to vote (for or against) whether there is value here. (...okay, now back to earth.)
  
[ ] First pass:
* The mental model. (Ignore the physical aspects at this point; just trying to start tackling the self-observation, reasoning and logic, and then how to start testing the logic assumptions for validity.)

[ ] Second pass:
* Physical learning. (If this robot were choosing to build itself a body to perform the physical steps needed to vet its mental model predictions how would it go about this.)
* Appendages? (Could appendages be modelled without any previous experience? Curious what these might look like or how they might evolve... would they be anything like human arms, legs, eyes, hands/feet with fingers/toes... etc. Bipedal? [ ] Future area for more thought.)

[ ] Third pass:
* Groups and cooperation. (If a mental and physical solution were to manifest, do it's outcomes improve by scaling it to multiple organisms/instances? [ ] More thought.)

[ ] What else? 
* Solving a fixed problem such as that of discovering and playing chess seems like a problem with a more knowable set of parameters... solving for the sun burning out or an unrecognized extinction event or the limits of moving sentience out across large geographic or spatial landscapes is a fascinating (and maybe important) area to try to contribute to the collective efforts. Can this evolve to help in any way?

[ ] Considerations
* Validation/Protection against malfunctioning robots. Some humans exhibit a tendancy to cause harm through bad or inaccurate information, or worse. Thinking about something like "the discovery of lying" here, where an actor might compete for a greater share through sabotage although it doesn't have to be nefarious, could just be a classic bias that is the trigger. How does the strategy and observation change to account for this and how might we go about quantifying the problem and scoping solutions.
